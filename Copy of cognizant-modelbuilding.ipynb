{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1P8ndpmve5j9PIV5tH2cRulcry3fM8UNC","timestamp":1757643530506}],"gpuType":"T4","mount_file_id":"1P8ndpmve5j9PIV5tH2cRulcry3fM8UNC","authorship_tag":"ABX9TyOs70/pmzAtbLZrGTs8wCnP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!git clone https://github.com/ig-quinzel/Cognizant-hackathon.git\n","%cd Cognizant-hackathon\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NPszZf5tl11G","executionInfo":{"status":"ok","timestamp":1757643469072,"user_tz":-330,"elapsed":930,"user":{"displayName":"Nandana","userId":"09707162195044241538"}},"outputId":"5f219c74-d86d-4664-d440-f3c0c58b5bb9"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Cognizant-hackathon'...\n","remote: Enumerating objects: 9, done.\u001b[K\n","remote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 9 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (9/9), 4.59 KiB | 4.59 MiB/s, done.\n","Resolving deltas: 100% (2/2), done.\n","/content/Cognizant-hackathon/Cognizant-hackathon\n"]}]},{"cell_type":"code","source":["!git checkout -b model_building\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3gL5DTytKjm","executionInfo":{"status":"ok","timestamp":1757643479142,"user_tz":-330,"elapsed":115,"user":{"displayName":"Nandana","userId":"09707162195044241538"}},"outputId":"b01a7c65-836a-41e0-e390-053f875633a2"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Switched to a new branch 'model_building'\n"]}]},{"cell_type":"code","source":["!git branch\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YZuJ8GbVsZzN","executionInfo":{"status":"ok","timestamp":1757643508000,"user_tz":-330,"elapsed":107,"user":{"displayName":"Nandana","userId":"09707162195044241538"}},"outputId":"5af49f0f-83d4-40c7-c506-08826a6b3d58"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["  main\u001b[m\n","* \u001b[32mmodel_building\u001b[m\n"]}]},{"cell_type":"code","source":["!mv \"/content/drive/MyDrive/Colab Notebooks/cognizant-modelbuilding.ipynb\" \"/content/Cognizant-hackathon/\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i1yZ2WwlmCSw","executionInfo":{"status":"ok","timestamp":1757643515230,"user_tz":-330,"elapsed":135,"user":{"displayName":"Nandana","userId":"09707162195044241538"}},"outputId":"1bfde063-9613-4307-ad80-a8adb6f8883a"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["mv: cannot stat '/content/drive/MyDrive/Colab Notebooks/cognizant-modelbuilding.ipynb': No such file or directory\n"]}]},{"cell_type":"code","source":["!git checkout model_building\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sgeu0Z0EslKA","executionInfo":{"status":"ok","timestamp":1757643168861,"user_tz":-330,"elapsed":109,"user":{"displayName":"Nandana","userId":"09707162195044241538"}},"outputId":"47e5fe95-ff18-4870-e624-548cbb0467df"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Already on 'model_building'\n"]}]},{"cell_type":"code","source":["!git config --global user.name \"ig-quinzel\"\n","!git config --global user.email \"nandanak267@gmail.com\"\n"],"metadata":{"id":"gbkKZCQdso1x","executionInfo":{"status":"ok","timestamp":1757643216625,"user_tz":-330,"elapsed":215,"user":{"displayName":"Nandana","userId":"09707162195044241538"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["!git add cognizant-modelbuilding.ipynb\n","!git commit -m \"Add initial notebook with model code\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jymWGd_qnYNa","executionInfo":{"status":"ok","timestamp":1757643367672,"user_tz":-330,"elapsed":219,"user":{"displayName":"Nandana","userId":"09707162195044241538"}},"outputId":"74aa2299-0a64-473d-ceb2-b4d6ea97bd8a"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[model_building 96f11cf] Add initial notebook with model code\n"," 2 files changed, 38 insertions(+), 2 deletions(-)\n"," rewrite README.md (100%)\n"," create mode 100644 cognizant-modelbuilding.ipynb\n"]}]},{"cell_type":"code","source":["!git push origin model_building\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0QRtzNZnkal","executionInfo":{"status":"ok","timestamp":1757643371336,"user_tz":-330,"elapsed":754,"user":{"displayName":"Nandana","userId":"09707162195044241538"}},"outputId":"4c21ade3-2382-4fd9-8852-b12a9764b6a1"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["To https://github.com/ig-quinzel/Cognizant-hackathon.git\n"," \u001b[31m! [rejected]       \u001b[m model_building -> model_building (non-fast-forward)\n","\u001b[31merror: failed to push some refs to 'https://github.com/ig-quinzel/Cognizant-hackathon.git'\n","\u001b[m\u001b[33mhint: Updates were rejected because the tip of your current branch is behind\u001b[m\n","\u001b[33mhint: its remote counterpart. Integrate the remote changes (e.g.\u001b[m\n","\u001b[33mhint: 'git pull ...') before pushing again.\u001b[m\n","\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n"]}]},{"cell_type":"code","source":["!git branch\n"],"metadata":{"id":"P5eMY3vcofcH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add .\n","!git commit -m \"Add notebook with initial code\"\n","\n"],"metadata":{"id":"e3kKOviaomSk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv \"/content/drive/MyDrive/Colab Notebooks/cognizant-modelbuilding.ipynb\" \"/content/Cognizant-hackathon/\"\n"],"metadata":{"id":"FfTo31PjpD1w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/Cognizant-hackathon/\n","!ls\n"],"metadata":{"id":"bsJWD8hMraWd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git reset --soft HEAD~1\n"],"metadata":{"id":"0E0sFwemrxtb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add .\n","!git commit -m \"Add initial notebook with model code\"\n","!git push origin model_building\n"],"metadata":{"id":"h8Aa7iA8reY7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBwnHprlNf5i"},"outputs":[],"source":["!pip install xgboost seaborn scikit-learn --quiet"]},{"cell_type":"code","source":["# ====================================\n","# 1. Setup: Install dependencies (if needed)\n","# ====================================\n","!pip install xgboost seaborn scikit-learn --quiet\n","\n","# ====================================\n","# 2. Import Libraries\n","# ====================================\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from xgboost import XGBRegressor\n","\n","# ====================================\n","# 3. Load Dataset\n","# ====================================\n","# If file is in Google Drive:\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# file_path = \"/content/drive/MyDrive/SYNTHETIC Markdown Dataset.csv\"\n","\n","# If you upload manually via Colab \"Upload file\":\n","from google.colab import files\n","uploaded = files.upload()\n","\n","file_path = list(uploaded.keys())[0]\n","df = pd.read_csv(file_path)\n","\n","print(\"Dataset Shape:\", df.shape)\n","df.head()\n"],"metadata":{"id":"jJVOiUijNmp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================\n","# 4. Encode Categorical Features\n","# ====================================\n","categorical_cols = [\"Category\", \"Brand\", \"Season\", \"Product_Name\", \"Promotion_Type\"]\n","encoders = {}\n","for col in categorical_cols:\n","    encoders[col] = LabelEncoder()\n","    df[col] = encoders[col].fit_transform(df[col])\n","\n","# ====================================\n","# 5. Define Features and Target\n","# ====================================\n","X = df.drop([\"Optimal Discount\"], axis=1)\n","y = df[\"Optimal Discount\"]\n","\n","# Scale numerical features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# ====================================\n","# 6. Train-Test Split\n","# ====================================\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y, test_size=0.2, random_state=42\n",")\n"],"metadata":{"id":"7tNjSwnmNqfe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"S8Ovn5RbcHZt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================\n","# 7. Train Model (XGBoost Regressor)\n","# ====================================\n","model = XGBRegressor(\n","    n_estimators=300,\n","    learning_rate=0.1,\n","    max_depth=6,\n","    subsample=0.8,\n","    colsample_bytree=0.8,\n","    random_state=42\n",")\n","\n","model.fit(X_train, y_train)\n","\n","# ====================================\n","# 8. Evaluate Model\n","# ====================================\n","y_pred = model.predict(X_test)\n","\n","mae = mean_absolute_error(y_test, y_pred)\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","r2 = r2_score(y_test, y_pred)\n","\n","print(\"✅ Model Performance\")\n","print(f\"MAE : {mae:.4f}\")\n","print(f\"RMSE: {rmse:.4f}\")\n","print(f\"R²  : {r2:.4f}\")\n"],"metadata":{"id":"H4p4419JNyLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================\n","# 9. Feature Importance\n","# ====================================\n","plt.figure(figsize=(10, 6))\n","sns.barplot(\n","    x=model.feature_importances_,\n","    y=X.columns\n",")\n","plt.title(\"Feature Importance for Dynamic Pricing\")\n","plt.show()\n"],"metadata":{"id":"2irPsWePNzSO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================\n","# 10. Predict Optimal Discount + Final Price\n","# ====================================\n","# Take one sample from test set\n","sample = X_test[0].reshape(1, -1)\n","pred_discount = model.predict(sample)[0]\n","\n","# Original price from the corresponding row\n","orig_price = df.iloc[X_test[0].argmax()][\"Original_Price\"] if hasattr(X_test, \"shape\") else None\n","# safer approach: pick first row index from y_test\n","sample_idx = y_test.index[0]\n","orig_price = df.loc[sample_idx, \"Original_Price\"]\n","\n","# Final recommended selling price\n","recommended_price = orig_price * (1 - pred_discount)\n","\n","print(f\"Predicted Optimal Discount: {pred_discount:.2f}\")\n","print(f\"Original Price: {orig_price:.2f}\")\n","print(f\"💰 Recommended Selling Price: {recommended_price:.2f}\")\n"],"metadata":{"id":"JRcizmpzN1O8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Example: Sales over time\n","plt.figure(figsize=(12,5))\n","plt.plot(df['date'], df['sales_units'], label='Sales Units')\n","plt.title(\"Historical Sales Over Time\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Units Sold\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"cMrGXaQ0pYUo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#\n","# ====================================\n","!pip install seaborn scikit-learn --quiet\n","\n","# ====================================\n","# 2. Import Libraries\n","# ====================================\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.ensemble import RandomForestRegressor\n","\n","# ====================================\n","# 3. Load Dataset\n","# ====================================\n","from google.colab import files\n","uploaded = files.upload()\n","\n","file_path = list(uploaded.keys())[0]\n","df = pd.read_csv(file_path)\n","\n","print(\"Dataset Shape:\", df.shape)\n","df.head()\n","\n","# ====================================\n","# 4. Encode Categorical Features\n","# ====================================\n","categorical_cols = [\"Category\", \"Brand\", \"Season\", \"Product_Name\", \"Promotion_Type\"]\n","encoders = {}\n","for col in categorical_cols:\n","    encoders[col] = LabelEncoder()\n","    df[col] = encoders[col].fit_transform(df[col])\n","\n","# ====================================\n","# 5. Define Features and Target\n","# ====================================\n","X = df.drop([\"Optimal Discount\"], axis=1)\n","y = df[\"Optimal Discount\"]\n","\n","# Scale numerical features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# ====================================\n","# 6. Train-Test Split\n","# ====================================\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_scaled, y, test_size=0.2, random_state=42\n",")\n","\n","# ====================================\n","# 7. Train Model (Random Forest Regressor)\n","# ====================================\n","rf_model = RandomForestRegressor(\n","    n_estimators=300,\n","    max_depth=None,\n","    min_samples_split=5,\n","    min_samples_leaf=2,\n","    random_state=42,\n","    n_jobs=-1\n",")\n","\n","rf_model.fit(X_train, y_train)\n","\n","# ====================================\n","# 8. Evaluate Model\n","# ====================================\n","y_pred = rf_model.predict(X_test)\n","\n","mae = mean_absolute_error(y_test, y_pred)\n","rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","r2 = r2_score(y_test, y_pred)\n","\n","print(\"✅ Random Forest Model Performance\")\n","print(f\"MAE : {mae:.4f}\")\n","print(f\"RMSE: {rmse:.4f}\")\n","print(f\"R²  : {r2:.4f}\")\n","\n","# ====================================\n","# 9. Feature Importance\n","# ====================================\n","plt.figure(figsize=(10, 6))\n","sns.barplot(\n","    x=rf_model.feature_importances_,\n","    y=X.columns\n",")\n","plt.title(\"Feature Importance for Dynamic Pricing (Random Forest)\")\n","plt.show()\n","\n","# ====================================\n","# 10. Predict Optimal Discount + Final Price\n","# ====================================\n","# Take one sample from test set\n","sample = X_test[0].reshape(1, -1)\n","pred_discount = rf_model.predict(sample)[0]\n","\n","# Original price from the corresponding row\n","sample_idx = y_test.index[0]\n","orig_price = df.loc[sample_idx, \"Original_Price\"]\n","\n","# Final recommended selling price\n","recommended_price = orig_price * (1 - pred_discount)\n","\n","print(f\"Predicted Optimal Discount: {pred_discount:.2f}\")\n","print(f\"Original Price: {orig_price:.2f}\")\n","print(f\"💰 Recommended Selling Price: {recommended_price:.2f}\")\n"],"metadata":{"id":"DTq-bV81cJEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Example: Sales over time\n","plt.figure(figsize=(12,5))\n","plt.plot(df['date'], df['sales_units'], label='Sales Units')\n","plt.title(\"Historical Sales Over Time\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Units Sold\")\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"26kL1TkMpP8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"__uOMnZHpW0g"},"execution_count":null,"outputs":[]}]}